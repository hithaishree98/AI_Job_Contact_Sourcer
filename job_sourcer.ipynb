{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U duckduckgo_search","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:21:30.264351Z","iopub.execute_input":"2025-12-02T00:21:30.264639Z","iopub.status.idle":"2025-12-02T00:21:35.924683Z","shell.execute_reply.started":"2025-12-02T00:21:30.264617Z","shell.execute_reply":"2025-12-02T00:21:35.923404Z"}},"outputs":[{"name":"stdout","text":"Collecting duckduckgo_search\n  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (8.3.0)\nCollecting primp>=0.15.0 (from duckduckgo_search)\n  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (5.4.0)\nDownloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\nDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: primp, duckduckgo_search\nSuccessfully installed duckduckgo_search-8.1.1 primp-0.15.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import asyncio\nimport csv\nimport json\nimport logging\nimport os\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nfrom google.adk.agents import LlmAgent, SequentialAgent, ParallelAgent\nfrom google.adk.events import Event\nfrom google.adk.models import Gemini\nfrom google.adk.runners import Runner, RunConfig\nfrom google.adk.sessions import DatabaseSessionService\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.genai import types as genai_types\nfrom duckduckgo_search import DDGS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:21:35.926867Z","iopub.execute_input":"2025-12-02T00:21:35.927203Z","iopub.status.idle":"2025-12-02T00:22:24.096471Z","shell.execute_reply.started":"2025-12-02T00:21:35.927163Z","shell.execute_reply":"2025-12-02T00:22:24.095485Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\", \"AIzaSyAyNPKZxz4Rk4R8LaGRk73TKLFSoxcQE3k\")\n\nAPP_NAME = \"job_hunt_agents_app\"\nDB_URL = \"sqlite:///my_agent_data.db\"\n\n# [CHANGE] Saving to Kaggle's working directory\nOUTPUT_CSV = Path(\"/kaggle/working/job_search_results.csv\")\n\nMAX_SEARCH_CALLS_PER_AGENT = 3\nMAX_TOTAL_LLM_CALLS = 80\nprint(OUTPUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.097451Z","iopub.execute_input":"2025-12-02T00:22:24.098063Z","iopub.status.idle":"2025-12-02T00:22:24.104927Z","shell.execute_reply.started":"2025-12-02T00:22:24.098033Z","shell.execute_reply":"2025-12-02T00:22:24.103969Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/job_search_results.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Configure Logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n    force=True\n)\nlogger = logging.getLogger(\"job_hunt_agents\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.107445Z","iopub.execute_input":"2025-12-02T00:22:24.107812Z","iopub.status.idle":"2025-12-02T00:22:24.224223Z","shell.execute_reply.started":"2025-12-02T00:22:24.107781Z","shell.execute_reply":"2025-12-02T00:22:24.223165Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --- 2. STATE MANAGEMENT ---\nclass StateKeys:\n    JOBS_LIST = \"jobs.list\"\n    JOBS_BY_PLATFORM = \"jobs.by_platform\"\n    CONTACTS_BY_COMPANY = \"contacts.by_company\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.224980Z","iopub.execute_input":"2025-12-02T00:22:24.225256Z","iopub.status.idle":"2025-12-02T00:22:24.244822Z","shell.execute_reply.started":"2025-12-02T00:22:24.225237Z","shell.execute_reply":"2025-12-02T00:22:24.243591Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def google_search(query: str) -> str:\n    \"\"\"\n    Performs a web search to find jobs, company pages, or contact info.\n    Returns a text summary of the top 5 results.\n    \"\"\"\n    logger.info(f\"ðŸ” Searching: {query}\")\n    try:\n        # Using DuckDuckGo for free, keyless search\n        results = DDGS().text(keywords=query, max_results=5)\n        if not results:\n            return \"No results found.\"\n        \n        output = []\n        for r in results:\n            title = r.get('title', 'No Title')\n            link = r.get('href', 'No Link')\n            body = r.get('body', 'No Snippet')\n            output.append(f\"Title: {title}\\nLink: {link}\\nSnippet: {body}\\n\")\n        \n        return \"\\n\".join(output)\n    except Exception as e:\n        logger.error(f\"Search failed: {e}\")\n        return f\"Search failed: {e}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.246596Z","iopub.execute_input":"2025-12-02T00:22:24.246867Z","iopub.status.idle":"2025-12-02T00:22:24.273536Z","shell.execute_reply.started":"2025-12-02T00:22:24.246847Z","shell.execute_reply":"2025-12-02T00:22:24.272404Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def append_jobs_to_state(\n    platform: str,\n    jobs: List[Dict[str, Any]],\n    tool_context: ToolContext,\n) -> Dict[str, Any]:\n    \"\"\"Appends parsed jobs to the session state.\"\"\"\n    state = tool_context.state\n    \n    # Defensive normalization\n    if not isinstance(jobs, list): jobs = []\n    \n    # Update platform-specific list\n    by_platform = state.get(StateKeys.JOBS_BY_PLATFORM, {})\n    existing = by_platform.get(platform, [])\n    existing.extend(jobs)\n    by_platform[platform] = existing\n    state[StateKeys.JOBS_BY_PLATFORM] = by_platform\n\n    # Update flat list\n    all_jobs = state.get(StateKeys.JOBS_LIST, [])\n    all_jobs.extend(jobs)\n    state[StateKeys.JOBS_LIST] = all_jobs\n\n    return {\"status\": \"ok\", \"platform\": platform, \"added\": len(jobs)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.274510Z","iopub.execute_input":"2025-12-02T00:22:24.274819Z","iopub.status.idle":"2025-12-02T00:22:24.300703Z","shell.execute_reply.started":"2025-12-02T00:22:24.274790Z","shell.execute_reply":"2025-12-02T00:22:24.299683Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def append_contacts_to_state(\n    contacts_by_company: Dict[str, Dict[str, List[str]]],\n    tool_context: ToolContext,\n) -> Dict[str, Any]:\n    \"\"\"Merges contact info into state.\"\"\"\n    state = tool_context.state\n    existing = state.get(StateKeys.CONTACTS_BY_COMPANY, {})\n\n    for company, roles in contacts_by_company.items():\n        key = (company or \"\").strip()\n        if not key: continue\n        \n        current = existing.get(key, {\"recruiters\": [], \"engineers\": [], \"managers\": []})\n        \n        for role in [\"recruiters\", \"engineers\", \"managers\"]:\n            names = roles.get(role, [])\n            if isinstance(names, list):\n                for n in names:\n                    if n and n not in current[role]:\n                        current[role].append(n)\n        \n        existing[key] = current\n\n    state[StateKeys.CONTACTS_BY_COMPANY] = existing\n    return {\"status\": \"ok\", \"companies_updated\": len(contacts_by_company)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.301643Z","iopub.execute_input":"2025-12-02T00:22:24.301939Z","iopub.status.idle":"2025-12-02T00:22:24.320118Z","shell.execute_reply.started":"2025-12-02T00:22:24.301913Z","shell.execute_reply":"2025-12-02T00:22:24.319195Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def merge_jobs_and_deduplicate(tool_context: ToolContext) -> Dict[str, Any]:\n    \"\"\"Deduplicates jobs based on (company, title, url).\"\"\"\n    state = tool_context.state\n    raw_by_platform = state.get(StateKeys.JOBS_BY_PLATFORM, {})\n    \n    seen = set()\n    merged = []\n    \n    for platform, jobs in raw_by_platform.items():\n        for j in jobs:\n            key = (\n                (j.get(\"company\") or \"\").strip().lower(),\n                (j.get(\"title\") or \"\").strip().lower(),\n                (j.get(\"url\") or \"\").strip()\n            )\n            if key in seen: continue\n            seen.add(key)\n            merged.append(j)\n            \n    state[StateKeys.JOBS_LIST] = merged\n    \n    unique_companies = { (j.get(\"company\") or \"\").strip() for j in merged if j.get(\"company\") }\n    \n    return {\n        \"status\": \"ok\",\n        \"total_jobs\": len(merged),\n        \"unique_companies\": len(unique_companies)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.321380Z","iopub.execute_input":"2025-12-02T00:22:24.321627Z","iopub.status.idle":"2025-12-02T00:22:24.377078Z","shell.execute_reply.started":"2025-12-02T00:22:24.321583Z","shell.execute_reply":"2025-12-02T00:22:24.375675Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def export_jobs_and_contacts_to_csv(\n    csv_path: str = str(OUTPUT_CSV),\n    tool_context: ToolContext = None\n) -> Dict[str, Any]:\n    \"\"\"Writes final data to CSV with 'Application Link' column.\"\"\"\n    state = tool_context.state\n    jobs = state.get(StateKeys.JOBS_LIST, [])\n    contacts_map = state.get(StateKeys.CONTACTS_BY_COMPANY, {})\n    \n    rows = []\n    for job in jobs:\n        company = (job.get(\"company\") or \"\").strip()\n        contacts = contacts_map.get(company, {})\n        \n        rows.append({\n            \"Company\": company,\n            \"Title\": job.get(\"title\"),\n            \"Location\": job.get(\"location\"),\n            \"Application Link\": job.get(\"url\"), # Renaming key for CSV clarity\n            \"Recruiters\": \", \".join(contacts.get(\"recruiters\", [])),\n            \"Engineers\": \", \".join(contacts.get(\"engineers\", [])),\n            \"Managers\": \", \".join(contacts.get(\"managers\", [])),\n        })\n\n    # Ensure the directory exists (important for /kaggle/working/)\n    import os\n    os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n\n    # Write to file\n    fieldnames = [\"Company\", \"Title\", \"Location\", \"Application Link\", \"Recruiters\", \"Engineers\", \"Managers\"]\n    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n        writer = csv.DictWriter(f, fieldnames=fieldnames)\n        writer.writeheader()\n        writer.writerows(rows)\n        \n    return {\"status\": \"ok\", \"rows_written\": len(rows), \"path\": csv_path}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.380342Z","iopub.execute_input":"2025-12-02T00:22:24.380716Z","iopub.status.idle":"2025-12-02T00:22:24.403157Z","shell.execute_reply.started":"2025-12-02T00:22:24.380694Z","shell.execute_reply":"2025-12-02T00:22:24.402095Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"retry_config = genai_types.HttpRetryOptions(attempts=4, initial_delay=1.0, max_delay=10.0, exp_base=2.0)\n\ndef make_gemini_llm() -> Gemini:\n    return Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.404159Z","iopub.execute_input":"2025-12-02T00:22:24.404438Z","iopub.status.idle":"2025-12-02T00:22:24.429366Z","shell.execute_reply.started":"2025-12-02T00:22:24.404416Z","shell.execute_reply":"2025-12-02T00:22:24.428269Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def platform_agent_instruction(platform_name: str, site_filter: str) -> str:\n    return f\"\"\"\nYou are a job-sourcing agent for {platform_name}.\n1. Use `Google Search` to find *Software Engineer* roles posted in the last 24h.\n   Query: `site:{site_filter} \"software engineer\" intitle:jobs after:2024-01-01` (adjust date as needed).\n2. Extract jobs into a list of dicts (title, company, location, url).\n3. Call `append_jobs_to_state` exactly once.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.430097Z","iopub.execute_input":"2025-12-02T00:22:24.430345Z","iopub.status.idle":"2025-12-02T00:22:24.451257Z","shell.execute_reply.started":"2025-12-02T00:22:24.430322Z","shell.execute_reply":"2025-12-02T00:22:24.450147Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def make_platform_agent(name: str, desc: str, filter_str: str) -> LlmAgent:\n    return LlmAgent(\n        name=name,\n        description=desc,\n        model=make_gemini_llm(),\n        instruction=platform_agent_instruction(desc, filter_str),\n        tools=[google_search, append_jobs_to_state] \n    )\n\n# Create Agents\nlever_agent = make_platform_agent(\"lever_agent\", \"Lever\", \"jobs.lever.co\")\ngreenhouse_agent = make_platform_agent(\"greenhouse_agent\", \"Greenhouse\", \"greenhouse.io\")\nworkday_agent = make_platform_agent(\"workday_agent\", \"Workday\", \"myworkdayjobs.com\")\n\njobs_parallel_agent = ParallelAgent(\n    name=\"jobs_parallel_agent\",\n    description=\"Runs job finders in parallel\",\n    sub_agents=[lever_agent, greenhouse_agent, workday_agent]\n)\n\nmerge_jobs_agent = LlmAgent(\n    name=\"merge_agent\",\n    description=\"Merges and deduplicates jobs\",\n    model=make_gemini_llm(),\n    instruction=\"Call `merge_jobs_and_deduplicate` once to consolidate the list.\",\n    tools=[merge_jobs_and_deduplicate]\n)\n\ncontacts_agent = LlmAgent(\n    name=\"contacts_agent\",\n    description=\"Finds people contacts\",\n    model=make_gemini_llm(),\n    instruction=\"\"\"\nFor the top 3 companies in the job list:\n1. Use `Google Search` to find names of recruiters or engineering managers.\n   Query example: `site:linkedin.com/in \"recruiter\" \"Company Name\"`\n2. Call `append_contacts_to_state` with the results.\n\"\"\",\n    tools=[google_search, append_contacts_to_state]\n)\n\ncsv_export_agent = LlmAgent(\n    name=\"csv_agent\",\n    description=\"Exports to CSV\",\n    model=make_gemini_llm(),\n    instruction=f\"Call `export_jobs_and_contacts_to_csv` to save results to {OUTPUT_CSV}.\",\n    tools=[export_jobs_and_contacts_to_csv]\n)\n\n# Root Orchestrator\nroot_orchestrator = SequentialAgent(\n    name=\"root_orchestrator\",\n    description=\"Main Workflow\",\n    sub_agents=[\n        jobs_parallel_agent,\n        merge_jobs_agent,\n        contacts_agent,\n        csv_export_agent\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.452251Z","iopub.execute_input":"2025-12-02T00:22:24.452504Z","iopub.status.idle":"2025-12-02T00:22:24.481306Z","shell.execute_reply.started":"2025-12-02T00:22:24.452487Z","shell.execute_reply":"2025-12-02T00:22:24.480337Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"session_service = DatabaseSessionService(db_url=DB_URL)\nrunner = Runner(agent=root_orchestrator, app_name=APP_NAME, session_service=session_service)\nlogger.info(\"âœ… System initialized successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:22:24.482324Z","iopub.execute_input":"2025-12-02T00:22:24.483066Z","iopub.status.idle":"2025-12-02T00:22:24.622494Z","shell.execute_reply.started":"2025-12-02T00:22:24.483037Z","shell.execute_reply":"2025-12-02T00:22:24.621289Z"}},"outputs":[{"name":"stderr","text":"2025-12-02 00:22:24,555 [INFO] google_adk.google.adk.sessions.database_session_service - Local timezone: Etc/UTC\n2025-12-02 00:22:24,618 [INFO] job_hunt_agents - âœ… System initialized successfully.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Add this as a new cell at the bottom to RUN the pipeline\nimport traceback\n\nasync def run_job_pipeline_async():\n    print(\"ðŸš€ Starting Job Hunt Pipeline...\")\n    \n    session_id = \"session_001\"\n    user_id = \"user\"\n\n    try:\n        # Create or Get Session\n        existing = await session_service.get_session(\n            app_name=APP_NAME, \n            user_id=user_id, \n            session_id=session_id\n        )\n        if not existing:\n            await session_service.create_session(\n                app_name=APP_NAME, \n                user_id=user_id, \n                session_id=session_id\n            )\n\n        # Run Agents\n        user_msg = genai_types.Content(\n            role=\"user\", \n            parts=[genai_types.Part(text=\"Find software engineer jobs, merge them, find contacts, and export to CSV.\")]\n        )\n        \n        agen = runner.run_async(\n            user_id=user_id, \n            session_id=session_id, \n            new_message=user_msg,\n            run_config=RunConfig(max_llm_calls=50)\n        )\n\n        async for event in agen:\n            if event.is_final_response() and event.content:\n                 print(f\"\\nðŸ¤– FINAL: {event.content.parts[0].text}\\n\")\n                 \n    except Exception as e:\n        traceback.print_exc()\n\n# Execute\nawait run_job_pipeline_async()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}