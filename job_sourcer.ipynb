{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-02T00:21:30.264639Z",
     "iopub.status.busy": "2025-12-02T00:21:30.264351Z",
     "iopub.status.idle": "2025-12-02T00:21:35.924683Z",
     "shell.execute_reply": "2025-12-02T00:21:35.923404Z",
     "shell.execute_reply.started": "2025-12-02T00:21:30.264617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo_search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (8.3.0)\n",
      "Collecting primp>=0.15.0 (from duckduckgo_search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (5.4.0)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: primp, duckduckgo_search\n",
      "Successfully installed duckduckgo_search-8.1.1 primp-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:21:35.927203Z",
     "iopub.status.busy": "2025-12-02T00:21:35.926867Z",
     "iopub.status.idle": "2025-12-02T00:22:24.096471Z",
     "shell.execute_reply": "2025-12-02T00:22:24.095485Z",
     "shell.execute_reply.started": "2025-12-02T00:21:35.927163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from google.adk.agents import LlmAgent, SequentialAgent, ParallelAgent\n",
    "from google.adk.events import Event\n",
    "from google.adk.models import Gemini\n",
    "from google.adk.runners import Runner, RunConfig\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types as genai_types\n",
    "from duckduckgo_search import DDGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.098063Z",
     "iopub.status.busy": "2025-12-02T00:22:24.097451Z",
     "iopub.status.idle": "2025-12-02T00:22:24.104927Z",
     "shell.execute_reply": "2025-12-02T00:22:24.103969Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.098033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/job_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\", \"Replace_api_key\")\n",
    "\n",
    "APP_NAME = \"job_hunt_agents_app\"\n",
    "DB_URL = \"sqlite:///my_agent_data.db\"\n",
    "\n",
    "# [CHANGE] Saving to Kaggle's working directory\n",
    "OUTPUT_CSV = Path(\"/kaggle/working/job_search_results.csv\")\n",
    "\n",
    "MAX_SEARCH_CALLS_PER_AGENT = 3\n",
    "MAX_TOTAL_LLM_CALLS = 80\n",
    "print(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.107812Z",
     "iopub.status.busy": "2025-12-02T00:22:24.107445Z",
     "iopub.status.idle": "2025-12-02T00:22:24.224223Z",
     "shell.execute_reply": "2025-12-02T00:22:24.223165Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.107781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "    force=True\n",
    ")\n",
    "logger = logging.getLogger(\"job_hunt_agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.225256Z",
     "iopub.status.busy": "2025-12-02T00:22:24.224980Z",
     "iopub.status.idle": "2025-12-02T00:22:24.244822Z",
     "shell.execute_reply": "2025-12-02T00:22:24.243591Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.225237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. STATE MANAGEMENT ---\n",
    "class StateKeys:\n",
    "    JOBS_LIST = \"jobs.list\"\n",
    "    JOBS_BY_PLATFORM = \"jobs.by_platform\"\n",
    "    CONTACTS_BY_COMPANY = \"contacts.by_company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.246867Z",
     "iopub.status.busy": "2025-12-02T00:22:24.246596Z",
     "iopub.status.idle": "2025-12-02T00:22:24.273536Z",
     "shell.execute_reply": "2025-12-02T00:22:24.272404Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.246847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def google_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a web search to find jobs, company pages, or contact info.\n",
    "    Returns a text summary of the top 5 results.\n",
    "    \"\"\"\n",
    "    logger.info(f\"ðŸ” Searching: {query}\")\n",
    "    try:\n",
    "        # Using DuckDuckGo for free, keyless search\n",
    "        results = DDGS().text(keywords=query, max_results=5)\n",
    "        if not results:\n",
    "            return \"No results found.\"\n",
    "        \n",
    "        output = []\n",
    "        for r in results:\n",
    "            title = r.get('title', 'No Title')\n",
    "            link = r.get('href', 'No Link')\n",
    "            body = r.get('body', 'No Snippet')\n",
    "            output.append(f\"Title: {title}\\nLink: {link}\\nSnippet: {body}\\n\")\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search failed: {e}\")\n",
    "        return f\"Search failed: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.274819Z",
     "iopub.status.busy": "2025-12-02T00:22:24.274510Z",
     "iopub.status.idle": "2025-12-02T00:22:24.300703Z",
     "shell.execute_reply": "2025-12-02T00:22:24.299683Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.274790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def append_jobs_to_state(\n",
    "    platform: str,\n",
    "    jobs: List[Dict[str, Any]],\n",
    "    tool_context: ToolContext,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Appends parsed jobs to the session state.\"\"\"\n",
    "    state = tool_context.state\n",
    "    \n",
    "    # Defensive normalization\n",
    "    if not isinstance(jobs, list): jobs = []\n",
    "    \n",
    "    # Update platform-specific list\n",
    "    by_platform = state.get(StateKeys.JOBS_BY_PLATFORM, {})\n",
    "    existing = by_platform.get(platform, [])\n",
    "    existing.extend(jobs)\n",
    "    by_platform[platform] = existing\n",
    "    state[StateKeys.JOBS_BY_PLATFORM] = by_platform\n",
    "\n",
    "    # Update flat list\n",
    "    all_jobs = state.get(StateKeys.JOBS_LIST, [])\n",
    "    all_jobs.extend(jobs)\n",
    "    state[StateKeys.JOBS_LIST] = all_jobs\n",
    "\n",
    "    return {\"status\": \"ok\", \"platform\": platform, \"added\": len(jobs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.301939Z",
     "iopub.status.busy": "2025-12-02T00:22:24.301643Z",
     "iopub.status.idle": "2025-12-02T00:22:24.320118Z",
     "shell.execute_reply": "2025-12-02T00:22:24.319195Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.301913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def append_contacts_to_state(\n",
    "    contacts_by_company: Dict[str, Dict[str, List[str]]],\n",
    "    tool_context: ToolContext,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Merges contact info into state.\"\"\"\n",
    "    state = tool_context.state\n",
    "    existing = state.get(StateKeys.CONTACTS_BY_COMPANY, {})\n",
    "\n",
    "    for company, roles in contacts_by_company.items():\n",
    "        key = (company or \"\").strip()\n",
    "        if not key: continue\n",
    "        \n",
    "        current = existing.get(key, {\"recruiters\": [], \"engineers\": [], \"managers\": []})\n",
    "        \n",
    "        for role in [\"recruiters\", \"engineers\", \"managers\"]:\n",
    "            names = roles.get(role, [])\n",
    "            if isinstance(names, list):\n",
    "                for n in names:\n",
    "                    if n and n not in current[role]:\n",
    "                        current[role].append(n)\n",
    "        \n",
    "        existing[key] = current\n",
    "\n",
    "    state[StateKeys.CONTACTS_BY_COMPANY] = existing\n",
    "    return {\"status\": \"ok\", \"companies_updated\": len(contacts_by_company)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.321627Z",
     "iopub.status.busy": "2025-12-02T00:22:24.321380Z",
     "iopub.status.idle": "2025-12-02T00:22:24.377078Z",
     "shell.execute_reply": "2025-12-02T00:22:24.375675Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.321583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def merge_jobs_and_deduplicate(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Deduplicates jobs based on (company, title, url).\"\"\"\n",
    "    state = tool_context.state\n",
    "    raw_by_platform = state.get(StateKeys.JOBS_BY_PLATFORM, {})\n",
    "    \n",
    "    seen = set()\n",
    "    merged = []\n",
    "    \n",
    "    for platform, jobs in raw_by_platform.items():\n",
    "        for j in jobs:\n",
    "            key = (\n",
    "                (j.get(\"company\") or \"\").strip().lower(),\n",
    "                (j.get(\"title\") or \"\").strip().lower(),\n",
    "                (j.get(\"url\") or \"\").strip()\n",
    "            )\n",
    "            if key in seen: continue\n",
    "            seen.add(key)\n",
    "            merged.append(j)\n",
    "            \n",
    "    state[StateKeys.JOBS_LIST] = merged\n",
    "    \n",
    "    unique_companies = { (j.get(\"company\") or \"\").strip() for j in merged if j.get(\"company\") }\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"total_jobs\": len(merged),\n",
    "        \"unique_companies\": len(unique_companies)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.380716Z",
     "iopub.status.busy": "2025-12-02T00:22:24.380342Z",
     "iopub.status.idle": "2025-12-02T00:22:24.403157Z",
     "shell.execute_reply": "2025-12-02T00:22:24.402095Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.380694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def export_jobs_and_contacts_to_csv(\n",
    "    csv_path: str = str(OUTPUT_CSV),\n",
    "    tool_context: ToolContext = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Writes final data to CSV with 'Application Link' column.\"\"\"\n",
    "    state = tool_context.state\n",
    "    jobs = state.get(StateKeys.JOBS_LIST, [])\n",
    "    contacts_map = state.get(StateKeys.CONTACTS_BY_COMPANY, {})\n",
    "    \n",
    "    rows = []\n",
    "    for job in jobs:\n",
    "        company = (job.get(\"company\") or \"\").strip()\n",
    "        contacts = contacts_map.get(company, {})\n",
    "        \n",
    "        rows.append({\n",
    "            \"Company\": company,\n",
    "            \"Title\": job.get(\"title\"),\n",
    "            \"Location\": job.get(\"location\"),\n",
    "            \"Application Link\": job.get(\"url\"), # Renaming key for CSV clarity\n",
    "            \"Recruiters\": \", \".join(contacts.get(\"recruiters\", [])),\n",
    "            \"Engineers\": \", \".join(contacts.get(\"engineers\", [])),\n",
    "            \"Managers\": \", \".join(contacts.get(\"managers\", [])),\n",
    "        })\n",
    "\n",
    "    # Ensure the directory exists (important for /kaggle/working/)\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n",
    "\n",
    "    # Write to file\n",
    "    fieldnames = [\"Company\", \"Title\", \"Location\", \"Application Link\", \"Recruiters\", \"Engineers\", \"Managers\"]\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "        \n",
    "    return {\"status\": \"ok\", \"rows_written\": len(rows), \"path\": csv_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.404438Z",
     "iopub.status.busy": "2025-12-02T00:22:24.404159Z",
     "iopub.status.idle": "2025-12-02T00:22:24.429366Z",
     "shell.execute_reply": "2025-12-02T00:22:24.428269Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.404416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retry_config = genai_types.HttpRetryOptions(attempts=4, initial_delay=1.0, max_delay=10.0, exp_base=2.0)\n",
    "\n",
    "def make_gemini_llm() -> Gemini:\n",
    "    return Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.430345Z",
     "iopub.status.busy": "2025-12-02T00:22:24.430097Z",
     "iopub.status.idle": "2025-12-02T00:22:24.451257Z",
     "shell.execute_reply": "2025-12-02T00:22:24.450147Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.430322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def platform_agent_instruction(platform_name: str, site_filter: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a job-sourcing agent for {platform_name}.\n",
    "1. Use `Google Search` to find *Software Engineer* roles posted in the last 24h.\n",
    "   Query: `site:{site_filter} \"software engineer\" intitle:jobs after:2024-01-01` (adjust date as needed).\n",
    "2. Extract jobs into a list of dicts (title, company, location, url).\n",
    "3. Call `append_jobs_to_state` exactly once.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.452504Z",
     "iopub.status.busy": "2025-12-02T00:22:24.452251Z",
     "iopub.status.idle": "2025-12-02T00:22:24.481306Z",
     "shell.execute_reply": "2025-12-02T00:22:24.480337Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.452487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_platform_agent(name: str, desc: str, filter_str: str) -> LlmAgent:\n",
    "    return LlmAgent(\n",
    "        name=name,\n",
    "        description=desc,\n",
    "        model=make_gemini_llm(),\n",
    "        instruction=platform_agent_instruction(desc, filter_str),\n",
    "        tools=[google_search, append_jobs_to_state] \n",
    "    )\n",
    "\n",
    "# Create Agents\n",
    "lever_agent = make_platform_agent(\"lever_agent\", \"Lever\", \"jobs.lever.co\")\n",
    "greenhouse_agent = make_platform_agent(\"greenhouse_agent\", \"Greenhouse\", \"greenhouse.io\")\n",
    "workday_agent = make_platform_agent(\"workday_agent\", \"Workday\", \"myworkdayjobs.com\")\n",
    "\n",
    "jobs_parallel_agent = ParallelAgent(\n",
    "    name=\"jobs_parallel_agent\",\n",
    "    description=\"Runs job finders in parallel\",\n",
    "    sub_agents=[lever_agent, greenhouse_agent, workday_agent]\n",
    ")\n",
    "\n",
    "merge_jobs_agent = LlmAgent(\n",
    "    name=\"merge_agent\",\n",
    "    description=\"Merges and deduplicates jobs\",\n",
    "    model=make_gemini_llm(),\n",
    "    instruction=\"Call `merge_jobs_and_deduplicate` once to consolidate the list.\",\n",
    "    tools=[merge_jobs_and_deduplicate]\n",
    ")\n",
    "\n",
    "contacts_agent = LlmAgent(\n",
    "    name=\"contacts_agent\",\n",
    "    description=\"Finds people contacts\",\n",
    "    model=make_gemini_llm(),\n",
    "    instruction=\"\"\"\n",
    "For the top 3 companies in the job list:\n",
    "1. Use `Google Search` to find names of recruiters or engineering managers.\n",
    "   Query example: `site:linkedin.com/in \"recruiter\" \"Company Name\"`\n",
    "2. Call `append_contacts_to_state` with the results.\n",
    "\"\"\",\n",
    "    tools=[google_search, append_contacts_to_state]\n",
    ")\n",
    "\n",
    "csv_export_agent = LlmAgent(\n",
    "    name=\"csv_agent\",\n",
    "    description=\"Exports to CSV\",\n",
    "    model=make_gemini_llm(),\n",
    "    instruction=f\"Call `export_jobs_and_contacts_to_csv` to save results to {OUTPUT_CSV}.\",\n",
    "    tools=[export_jobs_and_contacts_to_csv]\n",
    ")\n",
    "\n",
    "# Root Orchestrator\n",
    "root_orchestrator = SequentialAgent(\n",
    "    name=\"root_orchestrator\",\n",
    "    description=\"Main Workflow\",\n",
    "    sub_agents=[\n",
    "        jobs_parallel_agent,\n",
    "        merge_jobs_agent,\n",
    "        contacts_agent,\n",
    "        csv_export_agent\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T00:22:24.483066Z",
     "iopub.status.busy": "2025-12-02T00:22:24.482324Z",
     "iopub.status.idle": "2025-12-02T00:22:24.622494Z",
     "shell.execute_reply": "2025-12-02T00:22:24.621289Z",
     "shell.execute_reply.started": "2025-12-02T00:22:24.483037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 00:22:24,555 [INFO] google_adk.google.adk.sessions.database_session_service - Local timezone: Etc/UTC\n",
      "2025-12-02 00:22:24,618 [INFO] job_hunt_agents - âœ… System initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "session_service = DatabaseSessionService(db_url=DB_URL)\n",
    "runner = Runner(agent=root_orchestrator, app_name=APP_NAME, session_service=session_service)\n",
    "logger.info(\"âœ… System initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add this as a new cell at the bottom to RUN the pipeline\n",
    "import traceback\n",
    "\n",
    "async def run_job_pipeline_async():\n",
    "    print(\"ðŸš€ Starting Job Hunt Pipeline...\")\n",
    "    \n",
    "    session_id = \"session_001\"\n",
    "    user_id = \"user\"\n",
    "\n",
    "    try:\n",
    "        # Create or Get Session\n",
    "        existing = await session_service.get_session(\n",
    "            app_name=APP_NAME, \n",
    "            user_id=user_id, \n",
    "            session_id=session_id\n",
    "        )\n",
    "        if not existing:\n",
    "            await session_service.create_session(\n",
    "                app_name=APP_NAME, \n",
    "                user_id=user_id, \n",
    "                session_id=session_id\n",
    "            )\n",
    "\n",
    "        # Run Agents\n",
    "        user_msg = genai_types.Content(\n",
    "            role=\"user\", \n",
    "            parts=[genai_types.Part(text=\"Find software engineer jobs, merge them, find contacts, and export to CSV.\")]\n",
    "        )\n",
    "        \n",
    "        agen = runner.run_async(\n",
    "            user_id=user_id, \n",
    "            session_id=session_id, \n",
    "            new_message=user_msg,\n",
    "            run_config=RunConfig(max_llm_calls=50)\n",
    "        )\n",
    "\n",
    "        async for event in agen:\n",
    "            if event.is_final_response() and event.content:\n",
    "                 print(f\"\\nðŸ¤– FINAL: {event.content.parts[0].text}\\n\")\n",
    "                 \n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Execute\n",
    "await run_job_pipeline_async()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
